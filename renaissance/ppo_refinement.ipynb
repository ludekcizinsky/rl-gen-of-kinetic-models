{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d7635ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import os\n",
    "import helper as hp\n",
    "from configparser import ConfigParser\n",
    "from ppo_refinement import PPORefinement\n",
    "\n",
    "from kinetics.jacobian_solver import check_jacobian\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add5ed0",
   "metadata": {},
   "source": [
    "# Define PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f40e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, param_dim, hidden_dim=256):\n",
    "        super(Actor, self).__init__()\n",
    "        self.param_dim = param_dim\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, param_dim)\n",
    "        self.fc_log_std = nn.Linear(hidden_dim, param_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        log_std = self.fc_log_std(x)\n",
    "        # Clamp log_std to avoid extremely small or large std values\n",
    "        log_std = torch.clamp(log_std, -20, 2)\n",
    "        return mu, log_std\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim=256):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_value = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        value = self.fc_value(x)\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b040b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPORefinement:\n",
    "    def __init__(self, param_dim, noise_dim, reward_function,\n",
    "                 min_x_bounds, max_x_bounds,\n",
    "                 hidden_dim_actor=256, hidden_dim_critic=256,\n",
    "                 actor_lr=3e-4, critic_lr=1e-3,\n",
    "                 gamma=0.99, ppo_epochs=4, epsilon=0.2,\n",
    "                 gae_lambda=0.95, T_horizon=20,\n",
    "                 device=None):\n",
    "\n",
    "        self.param_dim = param_dim\n",
    "        self.noise_dim = noise_dim\n",
    "        self.state_dim = noise_dim + param_dim\n",
    "        self.reward_function = reward_function\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.min_x_bounds = torch.tensor(min_x_bounds, device=self.device, dtype=torch.float32)\n",
    "        self.max_x_bounds = torch.tensor(max_x_bounds, device=self.device, dtype=torch.float32)\n",
    "        if self.min_x_bounds.shape == (): # scalar\n",
    "            self.min_x_bounds = self.min_x_bounds.repeat(param_dim)\n",
    "        if self.max_x_bounds.shape == (): # scalar\n",
    "            self.max_x_bounds = self.max_x_bounds.repeat(param_dim)\n",
    "\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.ppo_epochs = ppo_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.T_horizon = T_horizon\n",
    "\n",
    "        self.actor = Actor(self.state_dim, param_dim, hidden_dim_actor).to(self.device)\n",
    "        self.critic = Critic(self.state_dim, hidden_dim_critic).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def _transform_to_bounded(self, params_raw):\n",
    "        # params_raw is the direct sample from the Gaussian distribution\n",
    "        # We apply tanh to make it [-1, 1] and then scale and shift\n",
    "        tanh_params = torch.tanh(params_raw)\n",
    "        return self.min_x_bounds + (self.max_x_bounds - self.min_x_bounds) * (tanh_params + 1) / 2.0\n",
    "\n",
    "    def _initialize_current_params_for_state(self):\n",
    "        # Start with parameters uniformly in the range of min_x_bounds and max_x_bounds\n",
    "        current_params_in_state = torch.rand(self.param_dim, device=self.device) * (self.max_x_bounds - self.min_x_bounds) + self.min_x_bounds\n",
    "        # Or use: torch.randn(self.param_dim, device=self.device) * 0.1 # Small random noise\n",
    "        # current_params_in_state = torch.randn(self.param_dim, device=self.device) * 0.1\n",
    "        return current_params_in_state\n",
    "\n",
    "\n",
    "    def collect_rollout_data(self):\n",
    "        states, actions_raw, log_probs_raw, rewards, dones, values = [], [], [], [], [], []\n",
    "\n",
    "        current_params_in_state = self._initialize_current_params_for_state().clone() # Shape: (param_dim)\n",
    "        final_ode_params = None\n",
    "\n",
    "        for t in range(self.T_horizon):\n",
    "            noise = torch.randn(self.noise_dim, device=self.device) # Shape: (noise_dim)\n",
    "            state_1d = torch.cat((noise, current_params_in_state.detach()), dim=0) # Shape: (state_dim)\n",
    "            state_batch = state_1d.unsqueeze(0) # Shape: (1, state_dim) for actor/critic\n",
    "\n",
    "            with torch.no_grad(): # During data collection, no grad needed for actor/critic forward pass\n",
    "                mu_raw, log_std_raw = self.actor(state_batch) # mu_raw: (1, param_dim), log_std_raw: (1, param_dim)\n",
    "                std_raw = torch.exp(log_std_raw)\n",
    "                dist = Normal(mu_raw, std_raw)\n",
    "                action_raw = dist.sample() # Shape: (1, param_dim)\n",
    "                action_log_prob_raw = dist.log_prob(action_raw).sum(dim=-1) # Shape: (1)\n",
    "                val = self.critic(state_batch) # Shape: (1, 1)\n",
    "\n",
    "            ode_params = self._transform_to_bounded(action_raw) # Shape: (1, param_dim)\n",
    "\n",
    "            if t == self.T_horizon - 1:\n",
    "                # Squeeze action_raw to 1D tensor for reward function\n",
    "                r = self.reward_function(ode_params.squeeze(0))\n",
    "                d = True\n",
    "                final_ode_params = ode_params.squeeze(0).detach()\n",
    "            else:\n",
    "                r = 0.0 # No intermediate rewards\n",
    "                d = False\n",
    "\n",
    "            states.append(state_1d) # Store 1D state\n",
    "            actions_raw.append(action_raw.squeeze(0)) # Store 1D action_raw\n",
    "            log_probs_raw.append(action_log_prob_raw.squeeze(0)) # Store scalar log_prob\n",
    "            rewards.append(torch.tensor(r, device=self.device, dtype=torch.float32))\n",
    "            dones.append(torch.tensor(d, device=self.device, dtype=torch.bool))\n",
    "            values.append(val.squeeze()) # Store scalar value\n",
    "\n",
    "            current_params_in_state = ode_params.squeeze(0) # Update for next state, Shape: (param_dim)\n",
    "\n",
    "        # Print mean reward for the episode\n",
    "        mean_reward = torch.mean(torch.stack(rewards)).item()\n",
    "        # print(f\"Mean reward for the episode: {mean_reward:.4f}\")\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        rollout_data = (\n",
    "            torch.stack(states),\n",
    "            torch.stack(actions_raw),\n",
    "            torch.stack(log_probs_raw),\n",
    "            torch.stack(rewards),\n",
    "            torch.stack(dones),\n",
    "            torch.stack(values)\n",
    "        )\n",
    "        return rollout_data, final_ode_params\n",
    "\n",
    "    def update_policy(self, rollout_data):\n",
    "        states, actions_raw, old_log_probs_raw, rewards, dones, old_values = rollout_data\n",
    "        old_values = old_values.detach() # Ensure no gradients flow back to critic from here\n",
    "\n",
    "        # Calculate advantages and returns using GAE\n",
    "        advantages = torch.zeros_like(rewards, device=self.device)\n",
    "        returns = torch.zeros_like(rewards, device=self.device)\n",
    "        gae = 0\n",
    "        # next_val for the last state is 0 because the episode terminates\n",
    "        next_val = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            # if dones[t] is True, (1.0 - dones[t].float()) will be 0\n",
    "            delta = rewards[t] + self.gamma * next_val * (1.0 - dones[t].float()) - old_values[t]\n",
    "            gae = delta + self.gamma * self.gae_lambda * (1.0 - dones[t].float()) * gae\n",
    "            advantages[t] = gae\n",
    "            returns[t] = gae + old_values[t] # Q_t = A_t + V(s_t)\n",
    "            next_val = old_values[t]\n",
    "\n",
    "        # Normalize advantages\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "        # Optimize policy and value network for K epochs\n",
    "        for _ in range(self.ppo_epochs):\n",
    "            # Actor update\n",
    "            mu_raw, log_std_raw = self.actor(states)\n",
    "            std_raw = torch.exp(log_std_raw)\n",
    "            dist_new = Normal(mu_raw, std_raw)\n",
    "            new_log_probs_raw = dist_new.log_prob(actions_raw).sum(dim=-1)\n",
    "\n",
    "            ratios = torch.exp(new_log_probs_raw - old_log_probs_raw.detach())\n",
    "\n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1 - self.epsilon, 1 + self.epsilon) * advantages\n",
    "            actor_loss = -torch.min(surr1, surr2).mean()\n",
    "            # Optional: Add entropy bonus\n",
    "            # entropy = dist_new.entropy().sum(-1).mean()\n",
    "            # actor_loss -= 0.01 * entropy\n",
    "\n",
    "\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            # Optional: Gradient clipping for actor\n",
    "            # torch.nn.utils.clip_grad_norm_(self.actor.parameters(), 0.5)\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            # Critic update\n",
    "            current_values = self.critic(states).squeeze(-1) # Shape: (T_horizon)\n",
    "            critic_loss = self.mse_loss(current_values, returns.detach())\n",
    "\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            # Optional: Gradient clipping for critic\n",
    "            # torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 0.5)\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "    def train(self, num_training_iterations, output_path=None):\n",
    "        print(f\"Training on {self.device}\")\n",
    "        final_rewards = []\n",
    "        for iteration in range(num_training_iterations):\n",
    "            rollout_data_tuple, final_ode_params = self.collect_rollout_data()\n",
    "            self.update_policy(rollout_data_tuple)\n",
    "\n",
    "            if final_ode_params is not None:\n",
    "                final_reward = self.reward_function(final_ode_params)\n",
    "                final_rewards.append(final_reward)\n",
    "                if (iteration + 1) % 1 == 0: # Log every iteration\n",
    "                    print(f\"Iteration {iteration+1}/{num_training_iterations}, Final Reward: {final_reward:.4f}\")\n",
    "                    # print(f\"   Final ODE Params: {final_ode_params.cpu().numpy()}\")\n",
    "            # save the model every 2 iterations\n",
    "            if (iteration + 1) % 100 == 0:\n",
    "                torch.save(self.actor.state_dict(), output_path + f\"actor_{iteration+1}.pth\")\n",
    "                torch.save(self.critic.state_dict(), output_path + f\"critic_{iteration+1}.pth\")\n",
    "                print(f\"Model saved at iteration {iteration+1}\")\n",
    "\n",
    "        # save final rewards\n",
    "        if output_path is not None:\n",
    "            np.save(output_path + \"final_rewards.npy\", final_rewards)\n",
    "            print(f\"Final rewards saved at {output_path}final_rewards.npy\")\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        # You can return the trained actor or save it\n",
    "        return self.actor, final_rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba82737",
   "metadata": {},
   "source": [
    "# Train PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "70e0c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse arguments from configfile\n",
    "configs = ConfigParser()\n",
    "configs.read('configfile.ini')\n",
    "\n",
    "n_samples = int(configs['MLP']['n_samples']) # Used by MLP for its internal sampling if any, and for p0 generation.\n",
    "\n",
    "lnminkm = float(configs['CONSTRAINTS']['min_km'])\n",
    "lnmaxkm = float(configs['CONSTRAINTS']['max_km'])\n",
    "\n",
    "repeats = int(configs['EVOSTRAT']['repeats'])\n",
    "generations = int(configs['EVOSTRAT']['generations']) # Will be used as num_iterations for PPO\n",
    "ss_idx = int(configs['EVOSTRAT']['ss_idx'])\n",
    "# n_threads = int(configs['EVOSTRAT']['n_threads']) # PPO collection is currently single-threaded\n",
    "\n",
    "output_path = configs['PATHS']['output_path']\n",
    "met_model = configs['PATHS']['met_model']\n",
    "names_km_config = hp.load_pkl(f'models/{met_model}/parameter_names_km_fdp1.pkl') # Full list of param names\n",
    "\n",
    "# Parameters needed directly by PPORefinement\n",
    "param_dim_config = int(configs['MLP']['no_kms'])\n",
    "latent_dim_config = int(configs['MLP']['latent_dim']) # For z vector in state\n",
    "\n",
    "\n",
    "# Call solvers from SKimPy (Used only for initial messages now)\n",
    "chk_jcbn = check_jacobian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "93349eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Load kinetic and thermodynamic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 18:32:01,208 - thermomodel_new - INFO - # Model initialized with units kcal/mol and temperature 298.15 K\n",
      "2025-05-13 18:32:03,060 - Unnamed - WARNING - Non integer stoichiometries found ['CYTBO3_4pp', 'LMPD_biomass_c_1_420', 'CYTBDpp'] change to integer for linear dependencies\n",
      "2025-05-13 18:32:03,360 - Unnamed - WARNING - Non integer stoichiometries found ['CYTBO3_4pp', 'LMPD_biomass_c_1_420', 'CYTBDpp'] change to integer for linear dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Load steady state data\n"
     ]
    }
   ],
   "source": [
    "# Integrate data\n",
    "print('---- Load kinetic and thermodynamic data')\n",
    "chk_jcbn._load_ktmodels(met_model, 'fdp1')           ## Load kinetic and thermodynamic data\n",
    "print('---- Load steady state data')\n",
    "chk_jcbn._load_ssprofile(met_model, 'fdp1', ss_idx)  ## Integrate steady state information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ac92538",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_partition = -2.5\n",
    "reward_flag = 0\n",
    "\n",
    "def _get_lambda_max(p_tensor_single):\n",
    "    p_numpy = p_tensor_single.detach().cpu().numpy()\n",
    "    # Use the stored chk_jcbn instance\n",
    "    chk_jcbn._prepare_parameters([p_numpy], names_km_config) \n",
    "    max_eig_list = chk_jcbn.calc_eigenvalues_recal_vmax()\n",
    "    max_eig_list.sort()\n",
    "\n",
    "    return max_eig_list\n",
    "\n",
    "def compute_reward(p_tensor_single, n_consider=10):\n",
    "    lambdas_val = _get_lambda_max(p_tensor_single)\n",
    "\n",
    "    if reward_flag == 0:\n",
    "        lambda_max_val = lambdas_val[0]\n",
    "        if lambda_max_val > 10:\n",
    "            return 0.0\n",
    "        r = 1.0 / (1.0 + np.exp(lambda_max_val - lambda_partition))\n",
    "    else:\n",
    "        considered_avg = sum(lambdas_val[:n_consider]) / n_consider\n",
    "        r = np.exp(-0.1 * considered_avg) / 2\n",
    "    # TODO: Right now, we are not using the Incidence part of the reward.\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e7f14b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Begin PPO refinement strategy\n",
      "Training on cpu\n",
      "Iteration 1/100, Final Reward: 0.0005\n",
      "Iteration 2/100, Final Reward: 0.1080\n",
      "Iteration 3/100, Final Reward: 0.6412\n",
      "Iteration 4/100, Final Reward: 0.2323\n",
      "Iteration 5/100, Final Reward: 0.1542\n",
      "Iteration 6/100, Final Reward: 0.1098\n",
      "Iteration 7/100, Final Reward: 0.0697\n",
      "Iteration 8/100, Final Reward: 0.0768\n",
      "Iteration 9/100, Final Reward: 0.0244\n",
      "Iteration 10/100, Final Reward: 0.0951\n",
      "Iteration 11/100, Final Reward: 0.1816\n",
      "Iteration 12/100, Final Reward: 0.0000\n",
      "Iteration 13/100, Final Reward: 0.0761\n",
      "Iteration 14/100, Final Reward: 0.0887\n",
      "Iteration 15/100, Final Reward: 0.0851\n",
      "Iteration 16/100, Final Reward: 0.0797\n",
      "Iteration 17/100, Final Reward: 0.1083\n",
      "Iteration 18/100, Final Reward: 0.0832\n",
      "Iteration 19/100, Final Reward: 0.1460\n",
      "Iteration 20/100, Final Reward: 0.0819\n",
      "Iteration 21/100, Final Reward: 0.0001\n",
      "Iteration 22/100, Final Reward: 0.1990\n",
      "Iteration 23/100, Final Reward: 0.0761\n",
      "Iteration 24/100, Final Reward: 0.1003\n",
      "Iteration 25/100, Final Reward: 0.0000\n",
      "Iteration 26/100, Final Reward: 0.0000\n",
      "Iteration 27/100, Final Reward: 0.0312\n",
      "Iteration 28/100, Final Reward: 0.1081\n",
      "Iteration 29/100, Final Reward: 0.0044\n",
      "Iteration 30/100, Final Reward: 0.0806\n",
      "Iteration 31/100, Final Reward: 0.1205\n",
      "Iteration 32/100, Final Reward: 0.0000\n",
      "Iteration 33/100, Final Reward: 0.1146\n",
      "Iteration 34/100, Final Reward: 0.0983\n",
      "Iteration 35/100, Final Reward: 0.1556\n",
      "Iteration 36/100, Final Reward: 0.1115\n",
      "Iteration 37/100, Final Reward: 0.1218\n",
      "Iteration 38/100, Final Reward: 0.0796\n",
      "Iteration 39/100, Final Reward: 0.0000\n",
      "Iteration 40/100, Final Reward: 0.1205\n",
      "Iteration 41/100, Final Reward: 0.1115\n",
      "Iteration 42/100, Final Reward: 0.1006\n",
      "Iteration 43/100, Final Reward: 0.0778\n",
      "Iteration 44/100, Final Reward: 0.1180\n",
      "Iteration 45/100, Final Reward: 0.0000\n",
      "Iteration 46/100, Final Reward: 0.1103\n",
      "Iteration 47/100, Final Reward: 0.0993\n",
      "Iteration 48/100, Final Reward: 0.1083\n",
      "Iteration 49/100, Final Reward: 0.0704\n",
      "Iteration 50/100, Final Reward: 0.0898\n",
      "Iteration 51/100, Final Reward: 0.4045\n",
      "Iteration 52/100, Final Reward: 0.2106\n",
      "Iteration 53/100, Final Reward: 0.0927\n",
      "Iteration 54/100, Final Reward: 0.0000\n",
      "Iteration 55/100, Final Reward: 0.0000\n",
      "Iteration 56/100, Final Reward: 0.0000\n",
      "Iteration 57/100, Final Reward: 0.0000\n",
      "Iteration 58/100, Final Reward: 0.0000\n",
      "Iteration 59/100, Final Reward: 0.1610\n",
      "Iteration 60/100, Final Reward: 0.0000\n",
      "Iteration 61/100, Final Reward: 0.0800\n",
      "Iteration 62/100, Final Reward: 0.3324\n",
      "Iteration 63/100, Final Reward: 0.0000\n",
      "Iteration 64/100, Final Reward: 0.0000\n",
      "Iteration 65/100, Final Reward: 0.0968\n",
      "Iteration 66/100, Final Reward: 0.1177\n",
      "Iteration 67/100, Final Reward: 0.0792\n",
      "Iteration 68/100, Final Reward: 0.1780\n",
      "Iteration 69/100, Final Reward: 0.0880\n",
      "Iteration 70/100, Final Reward: 0.0000\n",
      "Iteration 71/100, Final Reward: 0.1739\n",
      "Iteration 72/100, Final Reward: 0.1267\n",
      "Iteration 73/100, Final Reward: 0.2051\n",
      "Iteration 74/100, Final Reward: 0.0802\n",
      "Iteration 75/100, Final Reward: 0.0008\n",
      "Iteration 76/100, Final Reward: 0.0000\n",
      "Iteration 77/100, Final Reward: 0.1081\n",
      "Iteration 78/100, Final Reward: 0.1083\n",
      "Iteration 79/100, Final Reward: 0.1496\n",
      "Iteration 80/100, Final Reward: 0.0000\n",
      "Iteration 81/100, Final Reward: 0.1450\n",
      "Iteration 82/100, Final Reward: 0.0000\n",
      "Iteration 83/100, Final Reward: 0.0000\n",
      "Iteration 84/100, Final Reward: 0.0971\n",
      "Iteration 85/100, Final Reward: 0.0000\n",
      "Iteration 86/100, Final Reward: 0.0000\n",
      "Iteration 87/100, Final Reward: 0.1380\n",
      "Iteration 88/100, Final Reward: 0.0000\n",
      "Iteration 89/100, Final Reward: 0.1010\n",
      "Iteration 90/100, Final Reward: 0.0833\n",
      "Iteration 91/100, Final Reward: 0.0000\n",
      "Iteration 92/100, Final Reward: 0.0820\n",
      "Iteration 93/100, Final Reward: 0.1566\n",
      "Iteration 94/100, Final Reward: 0.1155\n",
      "Iteration 95/100, Final Reward: 0.1103\n",
      "Iteration 96/100, Final Reward: 0.0908\n",
      "Iteration 97/100, Final Reward: 0.1114\n",
      "Iteration 98/100, Final Reward: 0.0760\n",
      "Iteration 99/100, Final Reward: 0.1295\n",
      "Iteration 100/100, Final Reward: 0.1744\n",
      "Model saved at iteration 100\n",
      "Final rewards saved at output/ppo-refinement//ppo/final_rewards.npy\n",
      "Training finished.\n",
      "PPO training finished. Rewards log saved to output/ppo-refinement//ppo/\n"
     ]
    }
   ],
   "source": [
    "print('--- Begin PPO refinement strategy')\n",
    "\n",
    "this_savepath = f'{output_path}/ppo/' \n",
    "os.makedirs(this_savepath, exist_ok=True)\n",
    "\n",
    "ppo_agent = PPORefinement(\n",
    "    param_dim=param_dim_config,\n",
    "    noise_dim=latent_dim_config,\n",
    "    reward_function=compute_reward,\n",
    "    min_x_bounds=lnminkm,\n",
    "    max_x_bounds=lnmaxkm,\n",
    "    ppo_epochs=10,\n",
    "    T_horizon=1000,\n",
    "    actor_lr=1e-5,\n",
    "    critic_lr=5e-5,\n",
    ")\n",
    "\n",
    "trained_actor, rewards = ppo_agent.train(num_training_iterations=100, output_path=this_savepath)\n",
    "\n",
    "print(f\"PPO training finished. Rewards log saved to {this_savepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c41eacb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PPO Training Rewards')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Final Reward')\n",
    "plt.title('PPO Training Rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d76daa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy_incidence(trained_actor, ppo_agent, num_trials=50):\n",
    "    T_HORIZON = ppo_agent.T_horizon\n",
    "    NOISE_DIM = ppo_agent.noise_dim\n",
    "    N_TRIALS = num_trials\n",
    "    incidence = 0\n",
    "    for _ in range(N_TRIALS):\n",
    "        current_params_in_state = ppo_agent._initialize_current_params_for_state().clone()\n",
    "        generated_sequence = []\n",
    "        for _ in range(T_HORIZON):\n",
    "            noise = torch.randn(NOISE_DIM, device=ppo_agent.device)\n",
    "            state_1d = torch.cat((noise, current_params_in_state.detach()), dim=0)\n",
    "            state_batch = state_1d.unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                mu_raw, log_std_raw = trained_actor(state_batch)\n",
    "                # For generation, you might want to take the mean (mu_raw) or sample\n",
    "                # action_raw = mu_raw # Deterministic generation\n",
    "                action_raw = Normal(mu_raw, torch.exp(log_std_raw)).sample() # Stochastic generation\n",
    "            \n",
    "            ode_params = ppo_agent._transform_to_bounded(action_raw)\n",
    "            current_params_in_state = ode_params.squeeze(0)\n",
    "            generated_sequence.append(current_params_in_state.cpu().numpy())\n",
    "\n",
    "        final_generated_params = generated_sequence[-1]\n",
    "        final_reward_eval = compute_reward(torch.tensor(final_generated_params, device=ppo_agent.device))\n",
    "        lambda_max = _get_lambda_max(torch.tensor(final_generated_params, device=ppo_agent.device))[0]\n",
    "        if lambda_max < -2.5:\n",
    "            incidence += 1\n",
    "        print(f\"Final lambda_max: {lambda_max:.4f}\")\n",
    "        print(f\"Final reward: {final_reward_eval:.4f}\")\n",
    "    print(f\"Incidence over {N_TRIALS} trials: {incidence}/{N_TRIALS} = {incidence/N_TRIALS:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c091e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final lambda_max: -0.1772\n",
      "Final reward: 0.0893\n",
      "Final lambda_max: -1.0402\n",
      "Final reward: 0.1885\n",
      "Final lambda_max: 2.3507\n",
      "Final reward: 0.0078\n",
      "Final lambda_max: -1.1440\n",
      "Final reward: 0.2049\n",
      "Final lambda_max: 0.7898\n",
      "Final reward: 0.0359\n",
      "Final lambda_max: -1.2231\n",
      "Final reward: 0.2181\n",
      "Final lambda_max: -0.0087\n",
      "Final reward: 0.0765\n",
      "Final lambda_max: -0.5776\n",
      "Final reward: 0.1276\n",
      "Final lambda_max: -0.4455\n",
      "Final reward: 0.1136\n",
      "Final lambda_max: -0.3718\n",
      "Final reward: 0.1064\n",
      "Final lambda_max: 1.0836\n",
      "Final reward: 0.0270\n",
      "Final lambda_max: 0.4538\n",
      "Final reward: 0.0496\n",
      "Final lambda_max: -1.0335\n",
      "Final reward: 0.1875\n",
      "Final lambda_max: -0.0014\n",
      "Final reward: 0.0760\n",
      "Final lambda_max: -0.7611\n",
      "Final reward: 0.1495\n",
      "Final lambda_max: 2.8601\n",
      "Final reward: 0.0047\n",
      "Final lambda_max: 0.3451\n",
      "Final reward: 0.0549\n",
      "Final lambda_max: 3.6912\n",
      "Final reward: 0.0020\n",
      "Final lambda_max: -1.5115\n",
      "Final reward: 0.2712\n",
      "Final lambda_max: -0.5022\n",
      "Final reward: 0.1194\n",
      "Final lambda_max: -1.6429\n",
      "Final reward: 0.2979\n",
      "Final lambda_max: -0.9146\n",
      "Final reward: 0.1700\n",
      "Final lambda_max: 4.3165\n",
      "Final reward: 0.0011\n",
      "Final lambda_max: -0.7607\n",
      "Final reward: 0.1494\n",
      "Final lambda_max: -1.3589\n",
      "Final reward: 0.2421\n",
      "Final lambda_max: -1.5140\n",
      "Final reward: 0.2717\n",
      "Final lambda_max: 3.9820\n",
      "Final reward: 0.0015\n",
      "Final lambda_max: 2.0461\n",
      "Final reward: 0.0105\n",
      "Final lambda_max: -0.7096\n",
      "Final reward: 0.1430\n",
      "Final lambda_max: -1.7638\n",
      "Final reward: 0.3238\n",
      "Final lambda_max: 0.9000\n",
      "Final reward: 0.0323\n",
      "Final lambda_max: -1.5577\n",
      "Final reward: 0.2804\n",
      "Final lambda_max: -0.4445\n",
      "Final reward: 0.1135\n",
      "Final lambda_max: -0.9039\n",
      "Final reward: 0.1685\n",
      "Final lambda_max: -0.6185\n",
      "Final reward: 0.1322\n",
      "Final lambda_max: -0.4822\n",
      "Final reward: 0.1173\n",
      "Final lambda_max: -1.6960\n",
      "Final reward: 0.3092\n",
      "Final lambda_max: -0.9197\n",
      "Final reward: 0.1708\n",
      "Final lambda_max: -0.1816\n",
      "Final reward: 0.0896\n",
      "Final lambda_max: -1.3439\n",
      "Final reward: 0.2394\n",
      "Final lambda_max: 4.7495\n",
      "Final reward: 0.0007\n",
      "Final lambda_max: -1.1294\n",
      "Final reward: 0.2025\n",
      "Final lambda_max: -1.2053\n",
      "Final reward: 0.2151\n",
      "Final lambda_max: -0.1725\n",
      "Final reward: 0.0889\n",
      "Final lambda_max: -0.5969\n",
      "Final reward: 0.1298\n",
      "Final lambda_max: -1.8767\n",
      "Final reward: 0.3490\n",
      "Final lambda_max: -0.6014\n",
      "Final reward: 0.1303\n",
      "Final lambda_max: -0.9264\n",
      "Final reward: 0.1717\n",
      "Final lambda_max: -0.2883\n",
      "Final reward: 0.0987\n",
      "Final lambda_max: -1.9699\n",
      "Final reward: 0.3705\n",
      "Incidence over 50 trials: 0/50 = 0.00\n"
     ]
    }
   ],
   "source": [
    "evaluate_policy_incidence(trained_actor, ppo_agent, num_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03198d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
